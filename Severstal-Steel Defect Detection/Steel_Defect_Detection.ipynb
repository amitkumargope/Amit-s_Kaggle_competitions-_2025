{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322e3b89",
   "metadata": {},
   "source": [
    "# Severstal Steel Defect Detection\n",
    "\n",
    "This notebook implements a solution for the Severstal Steel Defect Detection competition. The goal is to localize and classify surface defects on steel sheets using semantic segmentation.\n",
    "\n",
    "## Competition Overview\n",
    "- **Task**: Semantic segmentation of steel defects\n",
    "- **Evaluation Metric**: Mean Dice Coefficient\n",
    "- **Classes**: 4 different types of defects\n",
    "- **Output Format**: Run-Length Encoded (RLE) pixel masks\n",
    "\n",
    "## Approach\n",
    "1. Data loading and preprocessing with RLE decoding\n",
    "2. U-Net based segmentation model\n",
    "3. Data augmentation using Albumentations\n",
    "4. Dice Loss for training\n",
    "5. RLE encoding for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1dd0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Segmentation Models\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Data Augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301000a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Paths\n",
    "    DATA_PATH = r'D:\\ML Practice\\Severstal Steel Defect Detection\\severstal-steel-defect-detection'\n",
    "    TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train_images')\n",
    "    TEST_IMG_PATH = os.path.join(DATA_PATH, 'test_images')\n",
    "    TRAIN_CSV = os.path.join(DATA_PATH, 'train.csv')\n",
    "    SAMPLE_SUBMISSION = os.path.join(DATA_PATH, 'sample_submission.csv')\n",
    "    \n",
    "    # Model parameters\n",
    "    ENCODER = 'resnet34'  # encoder for U-Net\n",
    "    ENCODER_WEIGHTS = 'imagenet'\n",
    "    CLASSES = 4  # number of defect classes\n",
    "    ACTIVATION = 'sigmoid'\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 4\n",
    "    NUM_EPOCHS = 30\n",
    "    LEARNING_RATE = 0.0001\n",
    "    \n",
    "    # Image parameters\n",
    "    IMG_HEIGHT = 256\n",
    "    IMG_WIDTH = 1600\n",
    "    \n",
    "    # Other\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    \n",
    "config = Config()\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb1377",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737d82db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLE encoding/decoding functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# RLE Encoding/Decoding Functions\n",
    "def rle_decode(mask_rle, shape=(256, 1600)):\n",
    "    \"\"\"\n",
    "    Decode run-length encoded mask.\n",
    "    \n",
    "    Args:\n",
    "        mask_rle: run-length as string formatted (start length)\n",
    "        shape: (height, width) of array to return \n",
    "    \n",
    "    Returns:\n",
    "        numpy array, 1 - mask, 0 - background\n",
    "    \"\"\"\n",
    "    if pd.isna(mask_rle) or mask_rle == '':\n",
    "        return np.zeros(shape[0] * shape[1], dtype=np.uint8).reshape(shape)\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    \n",
    "    return img.reshape(shape, order='F')\n",
    "\n",
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    Encode mask to run-length encoding.\n",
    "    \n",
    "    Args:\n",
    "        mask: numpy array, 1 - mask, 0 - background\n",
    "    \n",
    "    Returns:\n",
    "        run length as string formatted\n",
    "    \"\"\"\n",
    "    pixels = mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    \n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def mask2rle(mask):\n",
    "    \"\"\"\n",
    "    Convert mask to rle.\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    \"\"\"\n",
    "    pixels = mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def make_mask(df, image_name, shape=(256, 1600)):\n",
    "    \"\"\"\n",
    "    Create mask based on df, image name and shape.\n",
    "    \n",
    "    Args:\n",
    "        df: dataframe with ImageId_ClassId and EncodedPixels columns\n",
    "        image_name: name of image\n",
    "        shape: shape of the mask to create\n",
    "    \n",
    "    Returns:\n",
    "        mask with 4 channels for 4 defect classes\n",
    "    \"\"\"\n",
    "    encoded_masks = df.loc[df['ImageId'] == image_name, 'EncodedPixels']\n",
    "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
    "    \n",
    "    for idx, rle in enumerate(encoded_masks.values):\n",
    "        if pd.notna(rle):\n",
    "            masks[:, :, idx] = rle_decode(rle, shape)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "print(\"RLE encoding/decoding functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca07e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Dataset Class\n",
    "class SteelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for steel defect detection.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, data_folder, mean=None, std=None, phase='train', transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: dataframe with ImageId and EncodedPixels\n",
    "            data_folder: path to image folder\n",
    "            mean: normalization mean\n",
    "            std: normalization std\n",
    "            phase: 'train' or 'test'\n",
    "            transforms: albumentations transforms\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.data_folder = data_folder\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        self.mean = mean or [0.485, 0.456, 0.406]\n",
    "        self.std = std or [0.229, 0.224, 0.225]\n",
    "        \n",
    "        # Get unique image names\n",
    "        self.image_names = df['ImageId'].unique().tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.data_folder, image_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.phase == 'test':\n",
    "            # Apply transforms for test\n",
    "            if self.transforms:\n",
    "                augmented = self.transforms(image=image)\n",
    "                image = augmented['image']\n",
    "            return image, image_name\n",
    "        \n",
    "        # Create mask for training/validation\n",
    "        mask = make_mask(self.df, image_name, shape=(image.shape[0], image.shape[1]))\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        # Transpose mask to (C, H, W)\n",
    "        mask = mask.transpose(2, 0, 1)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "print(\"Dataset class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98531939",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dee5418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation transforms defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation Transforms\n",
    "def get_train_transforms(height=256, width=1600):\n",
    "    \"\"\"\n",
    "    Get training transforms with augmentation.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.0625,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=10,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.OneOf([\n",
    "            A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "            A.GridDistortion(p=0.5),\n",
    "            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=0.5),\n",
    "        ], p=0.3),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(p=0.5),\n",
    "            A.GaussianBlur(p=0.5),\n",
    "            A.MotionBlur(p=0.5),\n",
    "        ], p=0.3),\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.HueSaturationValue(p=0.5),\n",
    "            A.RandomGamma(p=0.5),\n",
    "        ], p=0.3),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_valid_transforms(height=256, width=1600):\n",
    "    \"\"\"\n",
    "    Get validation transforms without augmentation.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transforms(height=256, width=1600):\n",
    "    \"\"\"\n",
    "    Get test transforms.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "print(\"Augmentation transforms defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c14b0",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927f28b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "def build_model(encoder='resnet34', encoder_weights='imagenet', classes=4, activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build U-Net model for segmentation.\n",
    "    \n",
    "    Args:\n",
    "        encoder: encoder architecture\n",
    "        encoder_weights: pretrained weights\n",
    "        classes: number of output classes\n",
    "        activation: activation function\n",
    "    \n",
    "    Returns:\n",
    "        model\n",
    "    \"\"\"\n",
    "    model = smp.Unet(\n",
    "        encoder_name=encoder,\n",
    "        encoder_weights=encoder_weights,\n",
    "        classes=classes,\n",
    "        activation=activation,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Alternative: U-Net++\n",
    "def build_unetplusplus(encoder='resnet34', encoder_weights='imagenet', classes=4, activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build U-Net++ model for segmentation.\n",
    "    \"\"\"\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=encoder,\n",
    "        encoder_weights=encoder_weights,\n",
    "        classes=classes,\n",
    "        activation=activation,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Alternative: FPN\n",
    "def build_fpn(encoder='resnet34', encoder_weights='imagenet', classes=4, activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build FPN model for segmentation.\n",
    "    \"\"\"\n",
    "    model = smp.FPN(\n",
    "        encoder_name=encoder,\n",
    "        encoder_weights=encoder_weights,\n",
    "        classes=classes,\n",
    "        activation=activation,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Model architecture defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90835458",
   "metadata": {},
   "source": [
    "## 4. Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10806409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss functions and metrics defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Dice Coefficient Loss\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dice Loss for segmentation tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions: predicted masks (B, C, H, W)\n",
    "            targets: ground truth masks (B, C, H, W)\n",
    "        \n",
    "        Returns:\n",
    "            dice loss\n",
    "        \"\"\"\n",
    "        predictions = predictions.contiguous()\n",
    "        targets = targets.contiguous()\n",
    "        \n",
    "        intersection = (predictions * targets).sum(dim=2).sum(dim=2)\n",
    "        dice = (2. * intersection + self.smooth) / (\n",
    "            predictions.sum(dim=2).sum(dim=2) + targets.sum(dim=2).sum(dim=2) + self.smooth\n",
    "        )\n",
    "        \n",
    "        return 1 - dice.mean()\n",
    "\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Combined BCE and Dice Loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth=1.0, bce_weight=0.5):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_loss = DiceLoss(smooth=smooth)\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions: predicted logits (B, C, H, W)\n",
    "            targets: ground truth masks (B, C, H, W)\n",
    "        \n",
    "        Returns:\n",
    "            combined loss\n",
    "        \"\"\"\n",
    "        bce = self.bce_loss(predictions, targets)\n",
    "        predictions_sigmoid = torch.sigmoid(predictions)\n",
    "        dice = self.dice_loss(predictions_sigmoid, targets)\n",
    "        \n",
    "        return bce * self.bce_weight + dice * (1 - self.bce_weight)\n",
    "\n",
    "\n",
    "def dice_coefficient(predictions, targets, threshold=0.5, smooth=1.0):\n",
    "    \"\"\"\n",
    "    Calculate Dice coefficient metric.\n",
    "    \n",
    "    Args:\n",
    "        predictions: predicted masks (B, C, H, W)\n",
    "        targets: ground truth masks (B, C, H, W)\n",
    "        threshold: threshold for binarization\n",
    "        smooth: smoothing factor\n",
    "    \n",
    "    Returns:\n",
    "        dice coefficient\n",
    "    \"\"\"\n",
    "    predictions = (predictions > threshold).float()\n",
    "    targets = targets.float()\n",
    "    \n",
    "    intersection = (predictions * targets).sum(dim=2).sum(dim=2)\n",
    "    dice = (2. * intersection + smooth) / (\n",
    "        predictions.sum(dim=2).sum(dim=2) + targets.sum(dim=2).sum(dim=2) + smooth\n",
    "    )\n",
    "    \n",
    "    return dice.mean()\n",
    "\n",
    "print(\"Loss functions and metrics defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b198524",
   "metadata": {},
   "source": [
    "## 5. Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870de350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: model to train\n",
    "        dataloader: training dataloader\n",
    "        criterion: loss function\n",
    "        optimizer: optimizer\n",
    "        device: device to use\n",
    "    \n",
    "    Returns:\n",
    "        average loss, average dice\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    \n",
    "    for images, masks in progress_bar:\n",
    "        images = images.to(device, dtype=torch.float32)\n",
    "        masks = masks.to(device, dtype=torch.float32)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            dice = dice_coefficient(predictions, masks)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice.item()\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'dice': f'{dice.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_dice\n",
    "\n",
    "\n",
    "# Validation Function\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate model for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: model to validate\n",
    "        dataloader: validation dataloader\n",
    "        criterion: loss function\n",
    "        device: device to use\n",
    "    \n",
    "    Returns:\n",
    "        average loss, average dice\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Validation')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in progress_bar:\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            masks = masks.to(device, dtype=torch.float32)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            dice = dice_coefficient(predictions, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_dice += dice.item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'dice': f'{dice.item():.4f}'\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_dice\n",
    "\n",
    "print(\"Training and validation functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "365194de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, \n",
    "                num_epochs, device, model_path='best_model.pth'):\n",
    "    \"\"\"\n",
    "    Train model for multiple epochs.\n",
    "    \n",
    "    Args:\n",
    "        model: model to train\n",
    "        train_loader: training dataloader\n",
    "        valid_loader: validation dataloader\n",
    "        criterion: loss function\n",
    "        optimizer: optimizer\n",
    "        scheduler: learning rate scheduler\n",
    "        num_epochs: number of epochs\n",
    "        device: device to use\n",
    "        model_path: path to save best model\n",
    "    \n",
    "    Returns:\n",
    "        training history\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_dice': [],\n",
    "        'valid_loss': [],\n",
    "        'valid_dice': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_dice = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_dice = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation\n",
    "        valid_loss, valid_dice = validate_epoch(model, valid_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(valid_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_dice'].append(train_dice)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        history['valid_dice'].append(valid_dice)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'\\nTrain Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f}')\n",
    "        print(f'Valid Loss: {valid_loss:.4f} | Valid Dice: {valid_dice:.4f}')\n",
    "        print(f'Learning Rate: {current_lr:.6f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if valid_dice > best_dice:\n",
    "            best_dice = valid_dice\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f'âœ“ Model saved with Dice: {best_dice:.4f}')\n",
    "    \n",
    "    print(f'\\nBest Validation Dice: {best_dice:.4f}')\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"Training loop defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1166b40d",
   "metadata": {},
   "source": [
    "## 6. Prediction and Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6797ee4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction and submission functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Prediction Function\n",
    "def predict(model, dataloader, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Generate predictions for test data.\n",
    "    \n",
    "    Args:\n",
    "        model: trained model\n",
    "        dataloader: test dataloader\n",
    "        device: device to use\n",
    "        threshold: threshold for binarization\n",
    "    \n",
    "    Returns:\n",
    "        predictions dictionary\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = {}\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Predicting')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, image_names in progress_bar:\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Convert to numpy\n",
    "            outputs = outputs.cpu().numpy()\n",
    "            \n",
    "            # Store predictions\n",
    "            for i, image_name in enumerate(image_names):\n",
    "                predictions[image_name] = outputs[i]\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def post_process(probability, threshold=0.5, min_size=3500):\n",
    "    \"\"\"\n",
    "    Post-process predictions by thresholding and removing small objects.\n",
    "    \n",
    "    Args:\n",
    "        probability: predicted probability mask\n",
    "        threshold: threshold for binarization\n",
    "        min_size: minimum object size to keep\n",
    "    \n",
    "    Returns:\n",
    "        processed mask\n",
    "    \"\"\"\n",
    "    mask = (probability > threshold).astype(np.uint8)\n",
    "    \n",
    "    # Find contours\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
    "    \n",
    "    # Remove small objects\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] < min_size:\n",
    "            mask[labels == i] = 0\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def generate_submission(predictions, sample_submission_path, output_path='submission.csv', \n",
    "                       threshold=0.5, min_size=3500):\n",
    "    \"\"\"\n",
    "    Generate submission file from predictions.\n",
    "    \n",
    "    Args:\n",
    "        predictions: dictionary of predictions\n",
    "        sample_submission_path: path to sample submission\n",
    "        output_path: path to save submission\n",
    "        threshold: threshold for binarization\n",
    "        min_size: minimum object size\n",
    "    \n",
    "    Returns:\n",
    "        submission dataframe\n",
    "    \"\"\"\n",
    "    # Load sample submission\n",
    "    sample_submission = pd.read_csv(sample_submission_path)\n",
    "    \n",
    "    # Parse ImageId_ClassId\n",
    "    sample_submission['ImageId'] = sample_submission['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "    sample_submission['ClassId'] = sample_submission['ImageId_ClassId'].apply(lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    # Generate predictions\n",
    "    encoded_pixels = []\n",
    "    \n",
    "    for idx, row in tqdm(sample_submission.iterrows(), total=len(sample_submission), desc='Generating submission'):\n",
    "        image_name = row['ImageId']\n",
    "        class_id = row['ClassId'] - 1  # Convert to 0-indexed\n",
    "        \n",
    "        if image_name in predictions:\n",
    "            # Get prediction for this class\n",
    "            pred_mask = predictions[image_name][class_id]\n",
    "            \n",
    "            # Resize back to original size if needed\n",
    "            pred_mask = cv2.resize(pred_mask, (1600, 256), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Post-process\n",
    "            pred_mask = post_process(pred_mask, threshold=threshold, min_size=min_size)\n",
    "            \n",
    "            # Encode to RLE\n",
    "            if pred_mask.sum() > 0:\n",
    "                rle = rle_encode(pred_mask)\n",
    "            else:\n",
    "                rle = ''\n",
    "        else:\n",
    "            rle = ''\n",
    "        \n",
    "        encoded_pixels.append(rle)\n",
    "    \n",
    "    # Create submission\n",
    "    submission = pd.DataFrame({\n",
    "        'ImageId_ClassId': sample_submission['ImageId_ClassId'],\n",
    "        'EncodedPixels': encoded_pixels\n",
    "    })\n",
    "    \n",
    "    # Save submission\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    print(f'Submission saved to {output_path}')\n",
    "    \n",
    "    return submission\n",
    "\n",
    "print(\"Prediction and submission functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696502e",
   "metadata": {},
   "source": [
    "## 7. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08ff6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Visualization Functions\n",
    "def visualize_sample(df, image_folder, image_name, figsize=(20, 10)):\n",
    "    \"\"\"\n",
    "    Visualize image with masks for all defect classes.\n",
    "    \n",
    "    Args:\n",
    "        df: dataframe with annotations\n",
    "        image_folder: path to image folder\n",
    "        image_name: name of image to visualize\n",
    "        figsize: figure size\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create masks\n",
    "    masks = make_mask(df, image_name, shape=(image.shape[0], image.shape[1]))\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 5, figsize=figsize)\n",
    "    \n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    for i in range(4):\n",
    "        axes[i+1].imshow(image)\n",
    "        axes[i+1].imshow(masks[:, :, i], alpha=0.5, cmap='hot')\n",
    "        axes[i+1].set_title(f'Class {i+1}')\n",
    "        axes[i+1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_predictions(image, true_mask, pred_mask, figsize=(20, 5)):\n",
    "    \"\"\"\n",
    "    Visualize image, ground truth, and predictions.\n",
    "    \n",
    "    Args:\n",
    "        image: input image\n",
    "        true_mask: ground truth mask\n",
    "        pred_mask: predicted mask\n",
    "        figsize: figure size\n",
    "    \"\"\"\n",
    "    num_classes = true_mask.shape[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, num_classes + 1, figsize=figsize)\n",
    "    \n",
    "    # Original image\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.cpu().numpy().transpose(1, 2, 0)\n",
    "        # Denormalize\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = image * std + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "    \n",
    "    for i in range(3):\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title('Image')\n",
    "        axes[i, 0].axis('off')\n",
    "    \n",
    "    # Masks for each class\n",
    "    for class_idx in range(num_classes):\n",
    "        # Ground truth\n",
    "        axes[0, class_idx + 1].imshow(true_mask[class_idx], cmap='gray')\n",
    "        axes[0, class_idx + 1].set_title(f'GT Class {class_idx + 1}')\n",
    "        axes[0, class_idx + 1].axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        axes[1, class_idx + 1].imshow(pred_mask[class_idx], cmap='gray')\n",
    "        axes[1, class_idx + 1].set_title(f'Pred Class {class_idx + 1}')\n",
    "        axes[1, class_idx + 1].axis('off')\n",
    "        \n",
    "        # Overlay\n",
    "        axes[2, class_idx + 1].imshow(image)\n",
    "        axes[2, class_idx + 1].imshow(pred_mask[class_idx], alpha=0.5, cmap='hot')\n",
    "        axes[2, class_idx + 1].set_title(f'Overlay Class {class_idx + 1}')\n",
    "        axes[2, class_idx + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_history(history, figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Plot training history.\n",
    "    \n",
    "    Args:\n",
    "        history: training history dictionary\n",
    "        figsize: figure size\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(history['valid_loss'], label='Valid Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Dice\n",
    "    axes[1].plot(history['train_dice'], label='Train Dice')\n",
    "    axes[1].plot(history['valid_dice'], label='Valid Dice')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Dice Coefficient')\n",
    "    axes[1].set_title('Training and Validation Dice')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Learning rate\n",
    "    axes[2].plot(history['lr'])\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title('Learning Rate Schedule')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62439fe8",
   "metadata": {},
   "source": [
    "## 8. Main Execution - Data Loading and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3a973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (7095, 3)\n",
      "\n",
      "First few rows:\n",
      "         ImageId  ClassId                                      EncodedPixels\n",
      "0  0002cc93b.jpg        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
      "1  0007a71bf.jpg        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
      "2  000a4bcdd.jpg        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
      "3  000f6bf48.jpg        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
      "4  0014fce06.jpg        3  229501 11 229741 33 229981 55 230221 77 230468...\n",
      "5  0025bde0c.jpg        3  8458 14 8707 35 8963 48 9219 71 9475 88 9731 8...\n",
      "6  0025bde0c.jpg        4  315139 8 315395 15 315651 16 315906 17 316162 ...\n",
      "7  002af848d.jpg        4  290800 6 291055 13 291311 15 291566 18 291822 ...\n",
      "8  002fc4e19.jpg        1  146021 3 146275 10 146529 40 146783 46 147038 ...\n",
      "9  002fc4e19.jpg        2  145658 7 145901 20 146144 33 146386 47 146629 ...\n",
      "         ImageId  ClassId                                      EncodedPixels\n",
      "0  0002cc93b.jpg        1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
      "1  0007a71bf.jpg        3  18661 28 18863 82 19091 110 19347 110 19603 11...\n",
      "2  000a4bcdd.jpg        1  37607 3 37858 8 38108 14 38359 20 38610 25 388...\n",
      "3  000f6bf48.jpg        4  131973 1 132228 4 132483 6 132738 8 132993 11 ...\n",
      "4  0014fce06.jpg        3  229501 11 229741 33 229981 55 230221 77 230468...\n",
      "5  0025bde0c.jpg        3  8458 14 8707 35 8963 48 9219 71 9475 88 9731 8...\n",
      "6  0025bde0c.jpg        4  315139 8 315395 15 315651 16 315906 17 316162 ...\n",
      "7  002af848d.jpg        4  290800 6 291055 13 291311 15 291566 18 291822 ...\n",
      "8  002fc4e19.jpg        1  146021 3 146275 10 146529 40 146783 46 147038 ...\n",
      "9  002fc4e19.jpg        2  145658 7 145901 20 146144 33 146386 47 146629 ...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ImageId_ClassId'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Programming apps\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ImageId_ClassId'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Parse ImageId and ClassId\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageId_ClassId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageId_ClassId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Programming apps\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Programming apps\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ImageId_ClassId'"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv(config.TRAIN_CSV)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(train_df.head(10))\n",
    "\n",
    "# Parse ImageId and ClassId\n",
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "print(f\"\\nTotal images: {train_df['ImageId'].nunique()}\")\n",
    "print(f\"Total classes: {train_df['ClassId'].nunique()}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nImages with defects: {train_df['EncodedPixels'].notna().sum()}\")\n",
    "print(f\"Images without defects: {train_df['EncodedPixels'].isna().sum()}\")\n",
    "\n",
    "# Distribution of defects by class\n",
    "defect_counts = train_df[train_df['EncodedPixels'].notna()].groupby('ClassId').size()\n",
    "print(\"\\nDefect distribution by class:\")\n",
    "print(defect_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize defect distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Defects by class\n",
    "defect_counts.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_xlabel('Class ID')\n",
    "axes[0].set_ylabel('Number of Defects')\n",
    "axes[0].set_title('Distribution of Defects by Class')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Images with/without defects\n",
    "has_defect = train_df.groupby('ImageId')['EncodedPixels'].apply(lambda x: x.notna().any())\n",
    "defect_status = has_defect.value_counts()\n",
    "axes[1].pie(defect_status, labels=['With Defects', 'No Defects'], autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Images with/without Defects')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nImages with at least one defect: {has_defect.sum()}\")\n",
    "print(f\"Images with no defects: {(~has_defect).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd79190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images with defects\n",
    "# Find images with defects for each class\n",
    "sample_images = {}\n",
    "for class_id in range(1, 5):\n",
    "    images_with_class = train_df[(train_df['ClassId'] == class_id) & \n",
    "                                  (train_df['EncodedPixels'].notna())]['ImageId'].unique()\n",
    "    if len(images_with_class) > 0:\n",
    "        sample_images[class_id] = images_with_class[0]\n",
    "\n",
    "# Visualize one sample with all classes\n",
    "if sample_images:\n",
    "    sample_image = list(sample_images.values())[0]\n",
    "    print(f\"Visualizing sample image: {sample_image}\")\n",
    "    visualize_sample(train_df, config.TRAIN_IMG_PATH, sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d73a5",
   "metadata": {},
   "source": [
    "## 9. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation\n",
    "unique_images = train_df['ImageId'].unique()\n",
    "train_images, valid_images = train_test_split(\n",
    "    unique_images, \n",
    "    test_size=config.VALIDATION_SPLIT, \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Validation images: {len(valid_images)}\")\n",
    "\n",
    "# Create train and validation dataframes\n",
    "train_data = train_df[train_df['ImageId'].isin(train_images)].reset_index(drop=True)\n",
    "valid_data = train_df[train_df['ImageId'].isin(valid_images)].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTraining data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {valid_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_transforms = get_train_transforms(config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "valid_transforms = get_valid_transforms(config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "\n",
    "train_dataset = SteelDataset(\n",
    "    df=train_data,\n",
    "    data_folder=config.TRAIN_IMG_PATH,\n",
    "    phase='train',\n",
    "    transforms=train_transforms\n",
    ")\n",
    "\n",
    "valid_dataset = SteelDataset(\n",
    "    df=valid_data,\n",
    "    data_folder=config.TRAIN_IMG_PATH,\n",
    "    phase='train',\n",
    "    transforms=valid_transforms\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Valid dataset size: {len(valid_dataset)}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows compatibility\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Set to 0 for Windows compatibility\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
    "print(f\"Valid batches: {len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834d112",
   "metadata": {},
   "source": [
    "## 10. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c76a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = build_model(\n",
    "    encoder=config.ENCODER,\n",
    "    encoder_weights=config.ENCODER_WEIGHTS,\n",
    "    classes=config.CLASSES,\n",
    "    activation=None  # We'll use sigmoid in loss function\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"Model built and moved to {device}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e991fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer, and scheduler\n",
    "criterion = BCEDiceLoss(smooth=1.0, bce_weight=0.5)\n",
    "optimizer = Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Loss function, optimizer, and scheduler initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Note: Set NUM_EPOCHS to a smaller value (e.g., 2-3) for quick testing\n",
    "# For actual training, use 20-30 epochs\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=config.NUM_EPOCHS,\n",
    "    device=device,\n",
    "    model_path='best_steel_model.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ee817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd16977",
   "metadata": {},
   "source": [
    "## 11. Validation Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_steel_model.pth'))\n",
    "model.eval()\n",
    "print(\"Best model loaded!\")\n",
    "\n",
    "# Visualize predictions on validation set\n",
    "sample_idx = np.random.randint(0, len(valid_dataset))\n",
    "image, true_mask = valid_dataset[sample_idx]\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    image_tensor = image.unsqueeze(0).to(device)\n",
    "    output = model(image_tensor)\n",
    "    pred_mask = torch.sigmoid(output).cpu().numpy()[0]\n",
    "\n",
    "# Convert to binary\n",
    "pred_mask_binary = (pred_mask > 0.5).astype(np.float32)\n",
    "\n",
    "# Visualize\n",
    "visualize_predictions(image, true_mask, pred_mask_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607da3b",
   "metadata": {},
   "source": [
    "## 12. Test Set Predictions and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71529cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission to get test image names\n",
    "sample_submission = pd.read_csv(config.SAMPLE_SUBMISSION)\n",
    "sample_submission['ImageId'] = sample_submission['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Get unique test images\n",
    "test_images = sample_submission['ImageId'].unique()\n",
    "print(f\"Number of test images: {len(test_images)}\")\n",
    "\n",
    "# Create test dataframe\n",
    "test_df = pd.DataFrame({'ImageId': test_images})\n",
    "\n",
    "# Create test dataset\n",
    "test_transforms = get_test_transforms(config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "\n",
    "test_dataset = SteelDataset(\n",
    "    df=test_df,\n",
    "    data_folder=config.TEST_IMG_PATH,\n",
    "    phase='test',\n",
    "    transforms=test_transforms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "test_predictions = predict(model, test_loader, device, threshold=0.5)\n",
    "print(f\"Generated predictions for {len(test_predictions)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = generate_submission(\n",
    "    predictions=test_predictions,\n",
    "    sample_submission_path=config.SAMPLE_SUBMISSION,\n",
    "    output_path='submission.csv',\n",
    "    threshold=0.5,\n",
    "    min_size=3500\n",
    ")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nSubmission preview:\")\n",
    "print(submission.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb40b0e",
   "metadata": {},
   "source": [
    "## 13. Summary and Next Steps\n",
    "\n",
    "### What We've Built:\n",
    "1. **Data Loading**: RLE encoding/decoding for segmentation masks\n",
    "2. **Data Augmentation**: Comprehensive augmentation pipeline using Albumentations\n",
    "3. **Model**: U-Net architecture with ResNet34 encoder\n",
    "4. **Training**: BCE + Dice Loss with learning rate scheduling\n",
    "5. **Evaluation**: Dice coefficient metric\n",
    "6. **Submission**: RLE-encoded predictions\n",
    "\n",
    "### Key Features:\n",
    "- Multi-class segmentation for 4 defect types\n",
    "- State-of-the-art U-Net architecture with pretrained encoder\n",
    "- Combined loss function (BCE + Dice) for better segmentation\n",
    "- Post-processing to remove small false positives\n",
    "- Proper train/validation split\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Model Enhancements**:\n",
    "   - Try different encoders (ResNet50, EfficientNet, etc.)\n",
    "   - Experiment with U-Net++, FPN, or DeepLabV3+\n",
    "   - Ensemble multiple models\n",
    "\n",
    "2. **Data Augmentation**:\n",
    "   - Test Time Augmentation (TTA)\n",
    "   - More aggressive augmentations\n",
    "   - Class-specific augmentations\n",
    "\n",
    "3. **Post-processing**:\n",
    "   - Optimize threshold values per class\n",
    "   - Adjust minimum object size per class\n",
    "   - Morphological operations\n",
    "\n",
    "4. **Training**:\n",
    "   - Longer training with early stopping\n",
    "   - Different learning rate schedules\n",
    "   - Class balancing or weighted loss\n",
    "\n",
    "5. **Cross-Validation**:\n",
    "   - K-fold cross-validation for robust evaluation\n",
    "   - Stratified splitting based on defect presence\n",
    "\n",
    "### Usage:\n",
    "- Adjust `NUM_EPOCHS` in config for quick testing (2-3) or full training (20-30)\n",
    "- Modify threshold and min_size in submission generation for better results\n",
    "- Experiment with different model architectures by changing the encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
