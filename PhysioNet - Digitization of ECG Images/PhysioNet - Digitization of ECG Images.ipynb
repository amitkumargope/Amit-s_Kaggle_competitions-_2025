{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486bf660",
   "metadata": {},
   "source": [
    "# PhysioNet - ECG Image Digitization Challenge\n",
    "\n",
    "## Problem Statement\n",
    "Convert ECG images (scanned printouts, photos) into time-series data suitable for machine learning analysis. The challenge involves handling:\n",
    "- Physical artifacts (rotations, misalignments, blurring)\n",
    "- Multi-lead ECG interrelationships (12 leads)\n",
    "- Variable sampling frequencies and signal lengths\n",
    "- Different vendor formats and lead placements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930e62a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "from scipy.ndimage import rotate\n",
    "from skimage import transform, filters\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# Additional utilities\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea8f5d",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e835b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path('/kaggle/input/physionet-ecg-image-digitization/')\n",
    "\n",
    "# Explore directory structure\n",
    "print(\"Dataset Directory Structure:\")\n",
    "print(\"=\" * 60)\n",
    "if DATA_DIR.exists():\n",
    "    for item in sorted(DATA_DIR.rglob('*')):\n",
    "        if item.is_file():\n",
    "            print(f\"  {item.relative_to(DATA_DIR)} - {item.stat().st_size / 1024:.2f} KB\")\n",
    "        elif item.is_dir():\n",
    "            print(f\"üìÅ {item.relative_to(DATA_DIR)}/\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Data directory not found. Creating dummy structure for development...\")\n",
    "    # For local development, create a dummy structure\n",
    "    DATA_DIR = Path('./data')\n",
    "    DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec24557",
   "metadata": {},
   "source": [
    "## 3. ECG Image Preprocessing Pipeline\n",
    "\n",
    "Handle various image artifacts:\n",
    "- Rotation correction\n",
    "- Alignment and cropping\n",
    "- Noise reduction\n",
    "- Grid detection and removal\n",
    "- Lead segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3afc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGImagePreprocessor:\n",
    "    \"\"\"\n",
    "    Preprocesses ECG images to handle various artifacts and prepare for digitization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_size=(512, 512)):\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def detect_rotation(self, image):\n",
    "        \"\"\"Detect and correct rotation in ECG image using Hough line detection.\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        \n",
    "        # Detect lines using Hough transform\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, 100)\n",
    "        \n",
    "        if lines is not None:\n",
    "            angles = []\n",
    "            for rho, theta in lines[:, 0]:\n",
    "                angle = np.degrees(theta) - 90\n",
    "                if -45 < angle < 45:  # Only consider reasonable rotations\n",
    "                    angles.append(angle)\n",
    "            \n",
    "            if angles:\n",
    "                median_angle = np.median(angles)\n",
    "                return median_angle\n",
    "        return 0\n",
    "    \n",
    "    def rotate_image(self, image, angle):\n",
    "        \"\"\"Rotate image by given angle.\"\"\"\n",
    "        if abs(angle) < 0.5:  # Skip negligible rotations\n",
    "            return image\n",
    "        \n",
    "        (h, w) = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        \n",
    "        # Calculate new bounding box\n",
    "        cos = np.abs(M[0, 0])\n",
    "        sin = np.abs(M[0, 1])\n",
    "        new_w = int((h * sin) + (w * cos))\n",
    "        new_h = int((h * cos) + (w * sin))\n",
    "        \n",
    "        M[0, 2] += (new_w / 2) - center[0]\n",
    "        M[1, 2] += (new_h / 2) - center[1]\n",
    "        \n",
    "        rotated = cv2.warpAffine(image, M, (new_w, new_h), \n",
    "                                 flags=cv2.INTER_LINEAR,\n",
    "                                 borderMode=cv2.BORDER_CONSTANT,\n",
    "                                 borderValue=(255, 255, 255))\n",
    "        return rotated\n",
    "    \n",
    "    def remove_grid(self, image):\n",
    "        \"\"\"Remove grid lines from ECG image using morphological operations.\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        \n",
    "        # Detect grid using morphological operations\n",
    "        # Horizontal grid lines\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "        detect_horizontal = cv2.morphologyEx(gray, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "        \n",
    "        # Vertical grid lines\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
    "        detect_vertical = cv2.morphologyEx(gray, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
    "        \n",
    "        # Combine grid detection\n",
    "        grid_mask = cv2.add(detect_horizontal, detect_vertical)\n",
    "        \n",
    "        # Remove grid by inpainting\n",
    "        result = cv2.inpaint(gray, grid_mask, 3, cv2.INPAINT_TELEA)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def denoise_image(self, image):\n",
    "        \"\"\"Apply denoising while preserving ECG signal edges.\"\"\"\n",
    "        # Use bilateral filter to reduce noise while preserving edges\n",
    "        denoised = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "        return denoised\n",
    "    \n",
    "    def normalize_image(self, image):\n",
    "        \"\"\"Normalize image intensity and contrast.\"\"\"\n",
    "        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        normalized = clahe.apply(image)\n",
    "        return normalized\n",
    "    \n",
    "    def crop_to_content(self, image, margin=10):\n",
    "        \"\"\"Crop image to actual ECG content, removing excess borders.\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "        \n",
    "        # Threshold to find content\n",
    "        _, binary = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if contours:\n",
    "            # Get bounding box of all contours\n",
    "            x_min, y_min = image.shape[1], image.shape[0]\n",
    "            x_max, y_max = 0, 0\n",
    "            \n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                x_min = min(x_min, x)\n",
    "                y_min = min(y_min, y)\n",
    "                x_max = max(x_max, x + w)\n",
    "                y_max = max(y_max, y + h)\n",
    "            \n",
    "            # Add margin\n",
    "            x_min = max(0, x_min - margin)\n",
    "            y_min = max(0, y_min - margin)\n",
    "            x_max = min(image.shape[1], x_max + margin)\n",
    "            y_max = min(image.shape[0], y_max + margin)\n",
    "            \n",
    "            # Crop\n",
    "            cropped = image[y_min:y_max, x_min:x_max]\n",
    "            return cropped\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def preprocess(self, image_path):\n",
    "        \"\"\"Complete preprocessing pipeline.\"\"\"\n",
    "        # Load image\n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Detect and correct rotation\n",
    "        angle = self.detect_rotation(image)\n",
    "        image = self.rotate_image(image, angle)\n",
    "        \n",
    "        # Crop to content\n",
    "        image = self.crop_to_content(image)\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Remove grid\n",
    "        no_grid = self.remove_grid(image)\n",
    "        \n",
    "        # Denoise\n",
    "        denoised = self.denoise_image(no_grid)\n",
    "        \n",
    "        # Normalize\n",
    "        normalized = self.normalize_image(denoised)\n",
    "        \n",
    "        # Resize to target size\n",
    "        resized = cv2.resize(normalized, self.target_size, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        return resized\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = ECGImagePreprocessor(target_size=(1024, 1024))\n",
    "print(\"‚úì ECG Image Preprocessor initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe4de2e",
   "metadata": {},
   "source": [
    "## 4. Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for ECG image to time-series conversion.\n",
    "    Handles loading images and corresponding ground-truth signals.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, signal_paths=None, preprocessor=None, \n",
    "                 transform=None, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_paths: List of paths to ECG images\n",
    "            signal_paths: List of paths to ground-truth signal files (for training)\n",
    "            preprocessor: ECGImagePreprocessor instance\n",
    "            transform: PyTorch transforms for data augmentation\n",
    "            is_test: Whether this is test data (no ground truth available)\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.signal_paths = signal_paths\n",
    "        self.preprocessor = preprocessor\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # Standard 12-lead ECG lead names\n",
    "        self.lead_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', \n",
    "                          'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def load_signal(self, signal_path):\n",
    "        \"\"\"Load ground-truth ECG signal from file.\"\"\"\n",
    "        # Assuming signals are stored as numpy arrays or CSV files\n",
    "        if signal_path.endswith('.npy'):\n",
    "            signal = np.load(signal_path)\n",
    "        elif signal_path.endswith('.csv'):\n",
    "            signal = pd.read_csv(signal_path).values\n",
    "        else:\n",
    "            # Try to read as text file\n",
    "            signal = np.loadtxt(signal_path, delimiter=',')\n",
    "        \n",
    "        return signal.astype(np.float32)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load and preprocess image\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        if self.preprocessor:\n",
    "            image = self.preprocessor.preprocess(image_path)\n",
    "        else:\n",
    "            image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (1024, 1024))\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Convert to tensor (C, H, W)\n",
    "        image = torch.from_numpy(image).unsqueeze(0)\n",
    "        \n",
    "        # Apply transforms if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            # Return only image and ID for test set\n",
    "            record_id = Path(image_path).stem\n",
    "            return image, record_id\n",
    "        else:\n",
    "            # Load ground-truth signal for training\n",
    "            signal_path = self.signal_paths[idx]\n",
    "            signal = self.load_signal(signal_path)\n",
    "            \n",
    "            # Ensure signal is 2D: (num_leads, num_samples)\n",
    "            if signal.ndim == 1:\n",
    "                signal = signal.reshape(1, -1)\n",
    "            \n",
    "            signal = torch.from_numpy(signal)\n",
    "            \n",
    "            return image, signal\n",
    "\n",
    "# Data augmentation transforms for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomApply([\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
    "    ], p=0.3),\n",
    "    transforms.RandomApply([\n",
    "        transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01)  # Add noise\n",
    "    ], p=0.3),\n",
    "])\n",
    "\n",
    "print(\"‚úì ECG Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95772e7",
   "metadata": {},
   "source": [
    "## 5. Deep Learning Model Architecture\n",
    "\n",
    "**ECG Digitization Network**: A hybrid CNN-Transformer architecture that:\n",
    "1. **CNN Encoder**: Extracts spatial features from ECG images\n",
    "2. **Transformer Decoder**: Generates time-series sequences with attention mechanisms\n",
    "3. **Multi-Lead Decoder**: Produces all 12 ECG leads simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e93852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding for transformer.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN Encoder to extract features from ECG images.\n",
    "    Uses a pretrained ResNet backbone.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use ResNet34 as backbone\n",
    "        resnet = models.resnet34(pretrained=pretrained)\n",
    "        \n",
    "        # Modify first conv layer to accept 1-channel grayscale images\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if pretrained:\n",
    "            # Copy pretrained weights (average across RGB channels)\n",
    "            self.conv1.weight.data = resnet.conv1.weight.data.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        \n",
    "        # ResNet layers\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        \n",
    "        # Adaptive pooling to get fixed-size output\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((8, 8))\n",
    "        \n",
    "        # Feature dimension\n",
    "        self.feature_dim = 512  # ResNet34 output channels\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input: (batch, 1, H, W)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # Output: (batch, 512, 8, 8)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten spatial dimensions: (batch, 512, 64)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, self.feature_dim, -1)\n",
    "        x = x.permute(0, 2, 1)  # (batch, 64, 512)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer decoder to generate time-series from image features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model=512, nhead=8, num_layers=6, \n",
    "                 dim_feedforward=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        # Transformer decoder layers\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "    \n",
    "    def forward(self, memory, tgt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            memory: Encoded image features (batch, seq_len, d_model)\n",
    "            tgt: Target sequence (batch, tgt_len, d_model)\n",
    "        \"\"\"\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "        output = self.transformer_decoder(tgt, memory)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ECGDigitizationModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete model for ECG image digitization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_leads=12, max_signal_length=5000, \n",
    "                 d_model=512, nhead=8, num_decoder_layers=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_leads = num_leads\n",
    "        self.max_signal_length = max_signal_length\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # CNN Encoder\n",
    "        self.encoder = CNNEncoder(pretrained=True)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        self.decoder = TransformerDecoder(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_layers=num_decoder_layers,\n",
    "            dim_feedforward=2048,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        # Learnable query embeddings for each time step\n",
    "        self.query_embed = nn.Embedding(max_signal_length, d_model)\n",
    "        \n",
    "        # Output projection for each lead\n",
    "        self.output_projection = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(d_model, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(256, 1)\n",
    "            ) for _ in range(num_leads)\n",
    "        ])\n",
    "        \n",
    "        # Signal length prediction (adaptive to actual signal length)\n",
    "        self.length_predictor = nn.Sequential(\n",
    "            nn.Linear(d_model * 64, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, images, target_length=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images: ECG images (batch, 1, H, W)\n",
    "            target_length: Target signal length (optional)\n",
    "        \n",
    "        Returns:\n",
    "            signals: Predicted ECG signals (batch, num_leads, signal_length)\n",
    "            pred_length: Predicted signal length\n",
    "        \"\"\"\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        # Encode image\n",
    "        memory = self.encoder(images)  # (batch, 64, 512)\n",
    "        \n",
    "        # Predict signal length\n",
    "        memory_flat = memory.reshape(batch_size, -1)\n",
    "        length_ratio = self.length_predictor(memory_flat)  # (batch, 1)\n",
    "        pred_length = (length_ratio * self.max_signal_length).squeeze(-1)\n",
    "        \n",
    "        # Use target length if provided, otherwise use predicted\n",
    "        if target_length is None:\n",
    "            signal_length = int(pred_length.mean().item())\n",
    "        else:\n",
    "            signal_length = target_length\n",
    "        \n",
    "        signal_length = min(signal_length, self.max_signal_length)\n",
    "        \n",
    "        # Generate query embeddings\n",
    "        queries = self.query_embed.weight[:signal_length].unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decoder(memory, queries)  # (batch, signal_length, d_model)\n",
    "        \n",
    "        # Project to signals for each lead\n",
    "        signals = []\n",
    "        for lead_idx in range(self.num_leads):\n",
    "            lead_signal = self.output_projection[lead_idx](decoded)  # (batch, signal_length, 1)\n",
    "            signals.append(lead_signal.squeeze(-1))\n",
    "        \n",
    "        # Stack all leads: (batch, num_leads, signal_length)\n",
    "        signals = torch.stack(signals, dim=1)\n",
    "        \n",
    "        return signals, pred_length\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = ECGDigitizationModel(\n",
    "    num_leads=12,\n",
    "    max_signal_length=5000,\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_decoder_layers=6\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"‚úì ECG Digitization Model initialized\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6634a1a",
   "metadata": {},
   "source": [
    "## 6. Signal Alignment and SNR Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGAlignmentAndSNR:\n",
    "    \"\"\"\n",
    "    Implements the competition's modified SNR metric with signal alignment.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sampling_rate=500, max_time_shift=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sampling_rate: ECG sampling rate in Hz (default 500 Hz)\n",
    "            max_time_shift: Maximum time shift in seconds (default 0.2s)\n",
    "        \"\"\"\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.max_shift_samples = int(max_time_shift * sampling_rate)\n",
    "    \n",
    "    def find_time_alignment(self, pred_signal, true_signal):\n",
    "        \"\"\"\n",
    "        Find optimal time shift using cross-correlation.\n",
    "        \n",
    "        Args:\n",
    "            pred_signal: Predicted signal (1D array)\n",
    "            true_signal: Ground truth signal (1D array)\n",
    "        \n",
    "        Returns:\n",
    "            optimal_shift: Optimal shift in samples\n",
    "        \"\"\"\n",
    "        # Ensure same length by padding/truncating\n",
    "        min_len = min(len(pred_signal), len(true_signal))\n",
    "        pred_signal = pred_signal[:min_len]\n",
    "        true_signal = true_signal[:min_len]\n",
    "        \n",
    "        # Compute cross-correlation\n",
    "        correlation = signal.correlate(true_signal, pred_signal, mode='same')\n",
    "        \n",
    "        # Find peak within allowed shift range\n",
    "        center = len(correlation) // 2\n",
    "        start_idx = max(0, center - self.max_shift_samples)\n",
    "        end_idx = min(len(correlation), center + self.max_shift_samples + 1)\n",
    "        \n",
    "        local_correlation = correlation[start_idx:end_idx]\n",
    "        peak_idx = np.argmax(local_correlation)\n",
    "        optimal_shift = peak_idx + start_idx - center\n",
    "        \n",
    "        return optimal_shift\n",
    "    \n",
    "    def apply_time_shift(self, signal, shift):\n",
    "        \"\"\"\n",
    "        Apply time shift to signal.\n",
    "        \n",
    "        Args:\n",
    "            signal: Input signal\n",
    "            shift: Shift amount in samples (positive = shift right)\n",
    "        \n",
    "        Returns:\n",
    "            shifted_signal: Time-shifted signal\n",
    "        \"\"\"\n",
    "        if shift == 0:\n",
    "            return signal\n",
    "        \n",
    "        shifted = np.zeros_like(signal)\n",
    "        \n",
    "        if shift > 0:\n",
    "            # Shift right\n",
    "            shifted[shift:] = signal[:-shift]\n",
    "        else:\n",
    "            # Shift left\n",
    "            shifted[:shift] = signal[-shift:]\n",
    "        \n",
    "        return shifted\n",
    "    \n",
    "    def remove_vertical_offset(self, pred_signal, true_signal):\n",
    "        \"\"\"\n",
    "        Remove constant vertical offset between signals.\n",
    "        \n",
    "        Args:\n",
    "            pred_signal: Predicted signal\n",
    "            true_signal: Ground truth signal\n",
    "        \n",
    "        Returns:\n",
    "            corrected_signal: Prediction with offset removed\n",
    "        \"\"\"\n",
    "        offset = np.mean(pred_signal - true_signal)\n",
    "        return pred_signal - offset\n",
    "    \n",
    "    def calculate_snr(self, pred_signal, true_signal):\n",
    "        \"\"\"\n",
    "        Calculate SNR in decibels.\n",
    "        \n",
    "        Args:\n",
    "            pred_signal: Predicted signal\n",
    "            true_signal: Ground truth signal\n",
    "        \n",
    "        Returns:\n",
    "            snr_db: Signal-to-noise ratio in dB\n",
    "        \"\"\"\n",
    "        # Signal power (true signal)\n",
    "        signal_power = np.sum(true_signal ** 2)\n",
    "        \n",
    "        # Noise power (reconstruction error)\n",
    "        noise = pred_signal - true_signal\n",
    "        noise_power = np.sum(noise ** 2)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if noise_power == 0:\n",
    "            return np.inf\n",
    "        if signal_power == 0:\n",
    "            return -np.inf\n",
    "        \n",
    "        # SNR in dB\n",
    "        snr = signal_power / noise_power\n",
    "        snr_db = 10 * np.log10(snr)\n",
    "        \n",
    "        return snr_db\n",
    "    \n",
    "    def align_and_score(self, pred_signals, true_signals):\n",
    "        \"\"\"\n",
    "        Align predicted signals with ground truth and calculate SNR.\n",
    "        \n",
    "        Args:\n",
    "            pred_signals: Predicted signals (num_leads, signal_length)\n",
    "            true_signals: Ground truth signals (num_leads, signal_length)\n",
    "        \n",
    "        Returns:\n",
    "            snr_db: Overall SNR in dB\n",
    "            aligned_signals: Time and vertically aligned predictions\n",
    "        \"\"\"\n",
    "        num_leads = pred_signals.shape[0]\n",
    "        aligned_signals = []\n",
    "        \n",
    "        total_signal_power = 0\n",
    "        total_noise_power = 0\n",
    "        \n",
    "        for lead_idx in range(num_leads):\n",
    "            pred = pred_signals[lead_idx]\n",
    "            true = true_signals[lead_idx]\n",
    "            \n",
    "            # Ensure same length\n",
    "            min_len = min(len(pred), len(true))\n",
    "            pred = pred[:min_len]\n",
    "            true = true[:min_len]\n",
    "            \n",
    "            # Find and apply time alignment\n",
    "            shift = self.find_time_alignment(pred, true)\n",
    "            pred_aligned = self.apply_time_shift(pred, shift)\n",
    "            \n",
    "            # Remove vertical offset\n",
    "            pred_aligned = self.remove_vertical_offset(pred_aligned, true)\n",
    "            \n",
    "            aligned_signals.append(pred_aligned)\n",
    "            \n",
    "            # Accumulate powers across leads\n",
    "            total_signal_power += np.sum(true ** 2)\n",
    "            noise = pred_aligned - true\n",
    "            total_noise_power += np.sum(noise ** 2)\n",
    "        \n",
    "        # Calculate overall SNR\n",
    "        if total_noise_power == 0:\n",
    "            snr_db = np.inf\n",
    "        elif total_signal_power == 0:\n",
    "            snr_db = -np.inf\n",
    "        else:\n",
    "            snr = total_signal_power / total_noise_power\n",
    "            snr_db = 10 * np.log10(snr)\n",
    "        \n",
    "        return snr_db, np.array(aligned_signals)\n",
    "    \n",
    "    def batch_score(self, pred_batch, true_batch):\n",
    "        \"\"\"\n",
    "        Calculate average SNR for a batch of ECG records.\n",
    "        \n",
    "        Args:\n",
    "            pred_batch: Batch of predicted signals (batch, num_leads, signal_length)\n",
    "            true_batch: Batch of ground truth signals (batch, num_leads, signal_length)\n",
    "        \n",
    "        Returns:\n",
    "            avg_snr: Average SNR across all records in dB\n",
    "        \"\"\"\n",
    "        snr_scores = []\n",
    "        \n",
    "        for i in range(len(pred_batch)):\n",
    "            snr_db, _ = self.align_and_score(pred_batch[i], true_batch[i])\n",
    "            if not np.isinf(snr_db):\n",
    "                snr_scores.append(snr_db)\n",
    "        \n",
    "        if len(snr_scores) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return np.mean(snr_scores)\n",
    "\n",
    "\n",
    "# Initialize SNR calculator\n",
    "snr_calculator = ECGAlignmentAndSNR(sampling_rate=500, max_time_shift=0.2)\n",
    "print(\"‚úì SNR Calculator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00030f6d",
   "metadata": {},
   "source": [
    "## 7. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Combined loss function for ECG digitization.\n",
    "    Combines MSE, frequency domain loss, and morphological similarity.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=1.0, beta=0.5, gamma=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Weight for time-domain MSE loss\n",
    "            beta: Weight for frequency-domain loss\n",
    "            gamma: Weight for morphological loss\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def frequency_loss(self, pred, target):\n",
    "        \"\"\"\n",
    "        Loss in frequency domain using FFT.\n",
    "        \"\"\"\n",
    "        # Compute FFT\n",
    "        pred_fft = torch.fft.rfft(pred, dim=-1)\n",
    "        target_fft = torch.fft.rfft(target, dim=-1)\n",
    "        \n",
    "        # Compare magnitudes\n",
    "        pred_mag = torch.abs(pred_fft)\n",
    "        target_mag = torch.abs(target_fft)\n",
    "        \n",
    "        freq_loss = F.mse_loss(pred_mag, target_mag)\n",
    "        return freq_loss\n",
    "    \n",
    "    def morphological_loss(self, pred, target):\n",
    "        \"\"\"\n",
    "        Loss based on ECG morphological features (peaks, valleys).\n",
    "        \"\"\"\n",
    "        # Compute first derivative (slope)\n",
    "        pred_diff = pred[:, :, 1:] - pred[:, :, :-1]\n",
    "        target_diff = target[:, :, 1:] - target[:, :, :-1]\n",
    "        \n",
    "        # Compare derivatives\n",
    "        morph_loss = F.mse_loss(pred_diff, target_diff)\n",
    "        \n",
    "        return morph_loss\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: Predicted signals (batch, num_leads, signal_length)\n",
    "            target: Ground truth signals (batch, num_leads, signal_length)\n",
    "        \"\"\"\n",
    "        # Ensure same length\n",
    "        min_len = min(pred.size(-1), target.size(-1))\n",
    "        pred = pred[..., :min_len]\n",
    "        target = target[..., :min_len]\n",
    "        \n",
    "        # Time-domain MSE loss\n",
    "        time_loss = self.mse(pred, target)\n",
    "        \n",
    "        # Frequency-domain loss\n",
    "        freq_loss = self.frequency_loss(pred, target)\n",
    "        \n",
    "        # Morphological loss\n",
    "        morph_loss = self.morphological_loss(pred, target)\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = (self.alpha * time_loss + \n",
    "                     self.beta * freq_loss + \n",
    "                     self.gamma * morph_loss)\n",
    "        \n",
    "        return total_loss, {\n",
    "            'time_loss': time_loss.item(),\n",
    "            'freq_loss': freq_loss.item(),\n",
    "            'morph_loss': morph_loss.item()\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize loss function\n",
    "criterion = ECGLoss(alpha=1.0, beta=0.5, gamma=0.3)\n",
    "print(\"‚úì Loss function initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa7995",
   "metadata": {},
   "source": [
    "## 8. Training and Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327580bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGTrainer:\n",
    "    \"\"\"\n",
    "    Training and validation pipeline for ECG digitization model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, criterion, snr_calculator, device, \n",
    "                 learning_rate=1e-4, weight_decay=1e-5):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.snr_calculator = snr_calculator\n",
    "        self.device = device\n",
    "        \n",
    "        # Optimizer with different learning rates for encoder and decoder\n",
    "        encoder_params = list(model.encoder.parameters())\n",
    "        other_params = [p for name, p in model.named_parameters() \n",
    "                       if not name.startswith('encoder')]\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW([\n",
    "            {'params': encoder_params, 'lr': learning_rate * 0.1},  # Lower LR for pretrained encoder\n",
    "            {'params': other_params, 'lr': learning_rate}\n",
    "        ], weight_decay=weight_decay)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    "        )\n",
    "        \n",
    "        # History\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_snrs = []\n",
    "        self.best_snr = -np.inf\n",
    "    \n",
    "    def train_epoch(self, train_loader):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        loss_components = {'time_loss': 0, 'freq_loss': 0, 'morph_loss': 0}\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc='Training')\n",
    "        for batch_idx, (images, signals) in enumerate(pbar):\n",
    "            images = images.to(self.device)\n",
    "            signals = signals.to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred_signals, pred_length = self.model(images, target_length=signals.size(-1))\n",
    "            \n",
    "            # Compute loss\n",
    "            loss, components = self.criterion(pred_signals, signals)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            epoch_loss += loss.item()\n",
    "            for key in components:\n",
    "                loss_components[key] += components[key]\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'time': f'{components[\"time_loss\"]:.4f}',\n",
    "                'freq': f'{components[\"freq_loss\"]:.4f}'\n",
    "            })\n",
    "            \n",
    "            # Clear cache periodically\n",
    "            if batch_idx % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Average metrics\n",
    "        epoch_loss /= len(train_loader)\n",
    "        for key in loss_components:\n",
    "            loss_components[key] /= len(train_loader)\n",
    "        \n",
    "        return epoch_loss, loss_components\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        \"\"\"Validate model.\"\"\"\n",
    "        self.model.eval()\n",
    "        epoch_loss = 0\n",
    "        all_snr_scores = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(val_loader, desc='Validation')\n",
    "            for images, signals in pbar:\n",
    "                images = images.to(self.device)\n",
    "                signals = signals.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                pred_signals, pred_length = self.model(images, target_length=signals.size(-1))\n",
    "                \n",
    "                # Compute loss\n",
    "                loss, _ = self.criterion(pred_signals, signals)\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                # Compute SNR for each sample\n",
    "                pred_np = pred_signals.cpu().numpy()\n",
    "                true_np = signals.cpu().numpy()\n",
    "                \n",
    "                for i in range(len(pred_np)):\n",
    "                    snr_db, _ = self.snr_calculator.align_and_score(pred_np[i], true_np[i])\n",
    "                    if not np.isinf(snr_db):\n",
    "                        all_snr_scores.append(snr_db)\n",
    "                \n",
    "                # Update progress bar\n",
    "                if all_snr_scores:\n",
    "                    pbar.set_postfix({\n",
    "                        'loss': f'{loss.item():.4f}',\n",
    "                        'snr': f'{np.mean(all_snr_scores):.2f} dB'\n",
    "                    })\n",
    "        \n",
    "        epoch_loss /= len(val_loader)\n",
    "        avg_snr = np.mean(all_snr_scores) if all_snr_scores else 0.0\n",
    "        \n",
    "        return epoch_loss, avg_snr\n",
    "    \n",
    "    def train(self, train_loader, val_loader, num_epochs, save_dir='./checkpoints'):\n",
    "        \"\"\"Complete training loop.\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting Training for {num_epochs} epochs\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_components = self.train_epoch(train_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_snr = self.validate(val_loader)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_snrs.append(val_snr)\n",
    "            \n",
    "            # Update learning rate\n",
    "            self.scheduler.step(val_snr)\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(f\"\\n{'‚îÄ'*60}\")\n",
    "            print(f\"Epoch {epoch+1} Summary:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"    ‚îú‚îÄ Time Loss: {train_components['time_loss']:.4f}\")\n",
    "            print(f\"    ‚îú‚îÄ Freq Loss: {train_components['freq_loss']:.4f}\")\n",
    "            print(f\"    ‚îî‚îÄ Morph Loss: {train_components['morph_loss']:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"  Val SNR: {val_snr:.2f} dB\")\n",
    "            print(f\"  Best SNR: {self.best_snr:.2f} dB\")\n",
    "            print(f\"{'‚îÄ'*60}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_snr > self.best_snr:\n",
    "                self.best_snr = val_snr\n",
    "                checkpoint_path = os.path.join(save_dir, 'best_model.pth')\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'snr': val_snr,\n",
    "                    'loss': val_loss\n",
    "                }, checkpoint_path)\n",
    "                print(f\"‚úì Saved best model (SNR: {val_snr:.2f} dB)\")\n",
    "            \n",
    "            # Save checkpoint every 5 epochs\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'snr': val_snr,\n",
    "                    'loss': val_loss\n",
    "                }, checkpoint_path)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training Complete!\")\n",
    "        print(f\"Best Validation SNR: {self.best_snr:.2f} dB\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot losses\n",
    "        axes[0].plot(self.train_losses, label='Train Loss', marker='o')\n",
    "        axes[0].plot(self.val_losses, label='Val Loss', marker='s')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title('Training and Validation Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot SNR\n",
    "        axes[1].plot(self.val_snrs, label='Val SNR', marker='o', color='green')\n",
    "        axes[1].axhline(y=self.best_snr, color='r', linestyle='--', \n",
    "                       label=f'Best SNR: {self.best_snr:.2f} dB')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('SNR (dB)')\n",
    "        axes[1].set_title('Validation SNR')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"‚úì Trainer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90bee0",
   "metadata": {},
   "source": [
    "## 9. Data Preparation and Training Execution\n",
    "\n",
    "**Note**: This section assumes data is available at `/kaggle/input/physionet-ecg-image-digitization/`. \n",
    "Update paths according to actual dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f7244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_dir': Path('/kaggle/input/physionet-ecg-image-digitization/'),\n",
    "    'batch_size': 8,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    'val_split': 0.15,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(CONFIG['seed'])\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "def prepare_data_loaders(config):\n",
    "    \"\"\"\n",
    "    Prepare training and validation data loaders.\n",
    "    This is a template - adjust according to actual data structure.\n",
    "    \"\"\"\n",
    "    # Example: Assuming images are in 'train/images/' and signals in 'train/signals/'\n",
    "    train_image_dir = config['data_dir'] / 'train' / 'images'\n",
    "    train_signal_dir = config['data_dir'] / 'train' / 'signals'\n",
    "    \n",
    "    # Get all image files\n",
    "    image_paths = sorted(list(train_image_dir.glob('*.png')) + \n",
    "                        list(train_image_dir.glob('*.jpg')))\n",
    "    \n",
    "    # Corresponding signal files (adjust extension as needed)\n",
    "    signal_paths = [train_signal_dir / f\"{img.stem}.npy\" for img in image_paths]\n",
    "    \n",
    "    # Filter to only include samples where both image and signal exist\n",
    "    valid_samples = [(img, sig) for img, sig in zip(image_paths, signal_paths) \n",
    "                     if img.exists() and sig.exists()]\n",
    "    \n",
    "    if len(valid_samples) == 0:\n",
    "        print(\"‚ö†Ô∏è  No training data found. Using dummy data for demonstration...\")\n",
    "        # Create dummy data for testing the pipeline\n",
    "        return None, None\n",
    "    \n",
    "    image_paths, signal_paths = zip(*valid_samples)\n",
    "    \n",
    "    # Train-validation split\n",
    "    n_samples = len(image_paths)\n",
    "    n_val = int(n_samples * config['val_split'])\n",
    "    \n",
    "    indices = np.random.permutation(n_samples)\n",
    "    val_indices = indices[:n_val]\n",
    "    train_indices = indices[n_val:]\n",
    "    \n",
    "    train_image_paths = [image_paths[i] for i in train_indices]\n",
    "    train_signal_paths = [signal_paths[i] for i in train_indices]\n",
    "    val_image_paths = [image_paths[i] for i in val_indices]\n",
    "    val_signal_paths = [signal_paths[i] for i in val_indices]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ECGDataset(\n",
    "        train_image_paths, \n",
    "        train_signal_paths,\n",
    "        preprocessor=preprocessor,\n",
    "        transform=train_transforms,\n",
    "        is_test=False\n",
    "    )\n",
    "    \n",
    "    val_dataset = ECGDataset(\n",
    "        val_image_paths,\n",
    "        val_signal_paths,\n",
    "        preprocessor=preprocessor,\n",
    "        transform=None,\n",
    "        is_test=False\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Data prepared:\")\n",
    "    print(f\"  Training samples: {len(train_dataset)}\")\n",
    "    print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"  Batch size: {config['batch_size']}\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Prepare data loaders\n",
    "train_loader, val_loader = prepare_data_loaders(CONFIG)\n",
    "\n",
    "# Check if data is available\n",
    "if train_loader is not None:\n",
    "    print(\"\\n‚úì Data loaders ready for training\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Data not available. Training will be skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = ECGTrainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    snr_calculator=snr_calculator,\n",
    "    device=device,\n",
    "    learning_rate=CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# Start training (only if data is available)\n",
    "if train_loader is not None and val_loader is not None:\n",
    "    trainer.train(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=CONFIG['num_epochs'],\n",
    "        save_dir='./checkpoints'\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    trainer.plot_training_history()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping training - no data available\")\n",
    "    print(\"üí° Once data is available, uncomment and run this cell to train the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12e40e",
   "metadata": {},
   "source": [
    "## 10. Inference and Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138799d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(checkpoint_path, model, device):\n",
    "    \"\"\"Load the best trained model.\"\"\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"‚úì Loaded model from {checkpoint_path}\")\n",
    "        print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "        print(f\"  Validation SNR: {checkpoint['snr']:.2f} dB\")\n",
    "        return model\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Checkpoint not found: {checkpoint_path}\")\n",
    "        print(\"  Using untrained model for inference\")\n",
    "        return model\n",
    "\n",
    "\n",
    "def predict_on_test_set(model, test_loader, device):\n",
    "    \"\"\"Generate predictions for test set.\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, record_ids in tqdm(test_loader, desc='Generating predictions'):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Predict\n",
    "            pred_signals, pred_lengths = model(images)\n",
    "            \n",
    "            # Convert to numpy\n",
    "            pred_signals = pred_signals.cpu().numpy()\n",
    "            pred_lengths = pred_lengths.cpu().numpy()\n",
    "            \n",
    "            # Store predictions with IDs\n",
    "            for i, record_id in enumerate(record_ids):\n",
    "                predictions.append({\n",
    "                    'id': record_id,\n",
    "                    'signal': pred_signals[i],\n",
    "                    'length': pred_lengths[i]\n",
    "                })\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def create_submission(predictions, output_path='submission.csv'):\n",
    "    \"\"\"\n",
    "    Create submission file in the required format.\n",
    "    \n",
    "    Format: Each row contains (id, lead_name, time_step, value)\n",
    "    \"\"\"\n",
    "    submission_data = []\n",
    "    \n",
    "    lead_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', \n",
    "                  'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    \n",
    "    for pred in tqdm(predictions, desc='Creating submission'):\n",
    "        record_id = pred['id']\n",
    "        signal = pred['signal']  # (num_leads, signal_length)\n",
    "        \n",
    "        for lead_idx, lead_name in enumerate(lead_names):\n",
    "            lead_signal = signal[lead_idx]\n",
    "            \n",
    "            for time_step, value in enumerate(lead_signal):\n",
    "                submission_data.append({\n",
    "                    'id': f\"{record_id}_{lead_name}_{time_step}\",\n",
    "                    'value': value\n",
    "                })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úì Submission saved to {output_path}\")\n",
    "    print(f\"  Total predictions: {len(submission_df):,}\")\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "\n",
    "# Load best model\n",
    "best_model_path = './checkpoints/best_model.pth'\n",
    "model = load_best_model(best_model_path, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58094a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data loader\n",
    "def prepare_test_loader(config):\n",
    "    \"\"\"Prepare test data loader.\"\"\"\n",
    "    test_image_dir = config['data_dir'] / 'test' / 'images'\n",
    "    \n",
    "    if not test_image_dir.exists():\n",
    "        print(\"‚ö†Ô∏è  Test data directory not found\")\n",
    "        return None\n",
    "    \n",
    "    # Get all test images\n",
    "    test_image_paths = sorted(list(test_image_dir.glob('*.png')) + \n",
    "                             list(test_image_dir.glob('*.jpg')))\n",
    "    \n",
    "    if len(test_image_paths) == 0:\n",
    "        print(\"‚ö†Ô∏è  No test images found\")\n",
    "        return None\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = ECGDataset(\n",
    "        test_image_paths,\n",
    "        signal_paths=None,\n",
    "        preprocessor=preprocessor,\n",
    "        transform=None,\n",
    "        is_test=True\n",
    "    )\n",
    "    \n",
    "    # Create test loader\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Test data prepared: {len(test_dataset)} samples\")\n",
    "    return test_loader\n",
    "\n",
    "# Prepare test loader\n",
    "test_loader = prepare_test_loader(CONFIG)\n",
    "\n",
    "# Generate predictions\n",
    "if test_loader is not None:\n",
    "    predictions = predict_on_test_set(model, test_loader, device)\n",
    "    \n",
    "    # Create submission file\n",
    "    submission_df = create_submission(predictions, output_path='submission.csv')\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nSubmission preview:\")\n",
    "    print(submission_df.head(20))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Test data not available. Skipping prediction generation.\")\n",
    "    print(\"üí° Once test data is available, run this cell to generate predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2e499",
   "metadata": {},
   "source": [
    "## 11. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0acb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ecg_prediction(image, true_signal, pred_signal, snr_db=None, \n",
    "                            lead_names=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize ECG image alongside ground truth and predicted signals.\n",
    "    \n",
    "    Args:\n",
    "        image: Input ECG image\n",
    "        true_signal: Ground truth signals (num_leads, signal_length)\n",
    "        pred_signal: Predicted signals (num_leads, signal_length)\n",
    "        snr_db: SNR score in dB\n",
    "        lead_names: Names of ECG leads\n",
    "        save_path: Path to save figure\n",
    "    \"\"\"\n",
    "    if lead_names is None:\n",
    "        lead_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', \n",
    "                     'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    \n",
    "    num_leads = len(lead_names)\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    gs = fig.add_gridspec(num_leads + 1, 2, hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    # Plot image\n",
    "    ax_img = fig.add_subplot(gs[0, :])\n",
    "    if image.ndim == 3:\n",
    "        ax_img.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        ax_img.imshow(image, cmap='gray')\n",
    "    ax_img.set_title('ECG Image', fontsize=14, fontweight='bold')\n",
    "    ax_img.axis('off')\n",
    "    \n",
    "    # Plot each lead\n",
    "    for i, lead_name in enumerate(lead_names):\n",
    "        ax = fig.add_subplot(gs[i + 1, :])\n",
    "        \n",
    "        # Plot ground truth\n",
    "        ax.plot(true_signal[i], label='Ground Truth', color='blue', \n",
    "               linewidth=1.5, alpha=0.7)\n",
    "        \n",
    "        # Plot prediction\n",
    "        ax.plot(pred_signal[i], label='Prediction', color='red', \n",
    "               linewidth=1.5, alpha=0.7, linestyle='--')\n",
    "        \n",
    "        ax.set_ylabel(lead_name, fontsize=11, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        if i == 0:\n",
    "            ax.legend(loc='upper right')\n",
    "            if snr_db is not None:\n",
    "                ax.set_title(f'12-Lead ECG Signals (SNR: {snr_db:.2f} dB)', \n",
    "                           fontsize=12, fontweight='bold')\n",
    "        \n",
    "        if i == num_leads - 1:\n",
    "            ax.set_xlabel('Sample', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"‚úì Figure saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_sample_predictions(model, dataset, num_samples=3, device='cpu'):\n",
    "    \"\"\"\n",
    "    Visualize predictions for sample ECGs.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), size=min(num_samples, len(dataset)), \n",
    "                              replace=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in indices:\n",
    "            image, true_signal = dataset[idx]\n",
    "            \n",
    "            # Predict\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            pred_signal, _ = model(image_batch, target_length=true_signal.size(-1))\n",
    "            \n",
    "            # Convert to numpy\n",
    "            image_np = image.squeeze().cpu().numpy()\n",
    "            true_signal_np = true_signal.cpu().numpy()\n",
    "            pred_signal_np = pred_signal.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Calculate SNR\n",
    "            snr_db, aligned_pred = snr_calculator.align_and_score(\n",
    "                pred_signal_np, true_signal_np\n",
    "            )\n",
    "            \n",
    "            # Visualize\n",
    "            visualize_ecg_prediction(\n",
    "                image_np, \n",
    "                true_signal_np, \n",
    "                aligned_pred,\n",
    "                snr_db=snr_db\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nSample {idx} - SNR: {snr_db:.2f} dB\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# Visualize predictions on validation samples\n",
    "if val_loader is not None and len(val_loader.dataset) > 0:\n",
    "    print(\"Visualizing sample predictions on validation set...\\n\")\n",
    "    visualize_sample_predictions(model, val_loader.dataset, num_samples=3, device=device)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No validation data available for visualization\")\n",
    "    print(\"üí° This visualization will work once you have trained the model with actual data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
